<html>
<head>
  <title>2017-07-17-hello-world1</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/304720 (zh-CN, DDL); Windows/10.0.15063 (Win64);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="449"/>
<h1>2017-07-17-hello-world1</h1>

<div>
<span style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;"><div><br/></div><div style="text-align: center; font-size: 32px;"><b>HDFS节点多目录存放</b></div><div style="font-size: 19px;"><b><br/></b></div><div style="font-size: 19px;"><b>1.     名称节点多目录存放</b></div><div style="font-size: 19px;"><b><br/></b></div><div><div style="font-size: medium;"><div><b style="font-size: 16px;">    【hdfs-default.xml】</b></div><div style="font-size: 16px;">     &lt;property&gt;</div><span style="font-size: 16px;">          &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span></div><div style="font-size: medium;"><span style="font-size: 16px;">          &lt;value&gt;<b><font color="#FF0000">file://${hadoop.tmp</font></b></span><b><font color="#FF0000"><span style="font-size: 16px;">.dir</span><span style="font-size: 16px;"> }</span><span style="font-size: 16px;">/</span></font></b><span style="font-size: 16px;"><b><font color="#FF0000">dfs/name</font></b>&lt;/value&gt;</span></div><div style="font-size: medium;"><span style="font-size: 16px;">          &lt;description&gt;<font color="#A600C4">Determines where on the local filesystem the DFS name node</font></span></div><blockquote style="font-size: medium; margin: 0px 0px 0px 40px; border: none; padding: 0px;"><div><span style="font-size: 16px;"><font color="#A600C4">   should store the name table(fsimage).  If this is a comma-delimited list</font></span></div></blockquote><div style="font-size: medium;"><font color="#A600C4"><span style="font-size: 16px;">           of directories then the name table is replicated in all of the</span><br style="font-size: 16px;"/></font><span style="font-size: 16px;"><font color="#A600C4">           directories, for redundancy.</font> &lt;/description&gt;</span></div><div style="font-size: medium;"><span style="font-size: 16px;">     &lt;/property&gt;</span></div></div><div style="font-size: medium;"><span style="font-size: 16px;"><br/></span></div><div style="font-size: medium;"><span style="font-size: 16px;">     </span><b style="color: rgb(166, 0, 196); font-size: 16px;">决定了本地文件系统DFS NameNode存放name table（fsimage）的位置。如果此项是一个以逗号分隔的目录列表的话，那么</b><b style="color: rgb(166, 0, 196); font-size: 16px;">name table</b><b style="color: rgb(166, 0, 196); font-size: 16px;">将会在列表中的每一项中都存储一个副本。</b></div><div style="font-size: medium;"><b style="color: rgb(166, 0, 196); font-size: 16px;"><br/></b></div><div style="font-size: medium;"><b style="color: rgb(166, 0, 196); font-size: 16px;">   </b> <b style="font-size: 16px;"> <font color="#FF0000">如果配置多个目录去存储名称节点的本地数据，那么这些目录中存储的</font></b><font color="#FF0000"><b style="font-size: 16px;">内容</b><b style="font-size: 16px;">都是相同的。</b></font></div><div style="font-size: medium;"><b style="font-size: 16px;"><br/></b></div><div style="font-size: medium;"><b style="font-size: 16px;">     </b><b><span style="font-size: 16px;">dfs.namenode.name.dir = </span><span style="font-size: 16px;">file://${hadoop.tmp</span><span style="font-size: 16px;">.dir</span><span style="font-size: 16px;"> }</span><span style="font-size: 16px;">/</span><span style="font-size: 16px;">dfs/name1，</span><span style="font-size: 16px;">file://${hadoop.tmp</span><span style="font-size: 16px;">.dir</span><span style="font-size: 16px;"> }</span><span style="font-size: 16px;">/</span><span style="font-size: 16px;">dfs/name2</span></b></div><div style="font-size: medium;"><b><span style="font-size: 16px;"><br/></span></b></div><div style="font-size: medium;"><b style="font-size: 16px;">    【hdfs-site.xml】</b></div><div style="font-size: medium;"><b><span style="font-size: 16px;">     </span></b><span style="font-size: 16px;">&lt;property&gt;</span></div><div><span style="font-size: 16px;">          &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br style="font-size: 16px;"/></div><div><span style="font-size: 16px;">          &lt;value&gt;</span><b><span style="font-size: 16px;">file://${hadoop.tmp</span><span style="font-size: 16px;">.dir</span><span style="font-size: 16px;"> }</span><span style="font-size: 16px;">/</span><span style="font-size: 16px;">dfs/name1，</span><span style="font-size: 16px;">file://${hadoop.tmp</span><span style="font-size: 16px;">.dir</span><span style="font-size: 16px;"> }</span><span style="font-size: 16px;">/</span><span style="font-size: 16px;">dfs/name2</span></b><span style="font-size: 16px;">&lt;/value&gt;</span></div><div><span style="font-size: 16px;">     &lt;/property&gt;</span></div><div><span style="font-size: 16px;"><br/></span></div><div style="text-align: center;"><img src="2017-07-17-hello-world1_files/Image.png" type="image/png" style="cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: left;">      <span style="font-size: 16px;"><b><font color="#FF0000">name1和name2中存放的内容完全一致。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000">     </font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000">     </font><font color="#A600C4">通过名称节点配置多个目录能够提高可靠性，比如一台主机的挂载了多块磁盘，可以将目录配置在不同磁盘上，如果一个磁盘挂掉，那么还有另外一个磁盘作为备份。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000"><br/></font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000">   </font> <font color="#A600C4"> 辅助名称节点是在主机的层面上对名称节点进行备份。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000"><br/></font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000">   </font> <font color="#A600C4"> </font><font color="#FF0000">数据节点也可以配置多个目录，但作用与名称节点不同。</font><font color="#A600C4">数据节点所配置的不同目录是用来存放数据节点的本地数据的，也就是使用多个目录来存放它的本地数据，而这些目录中的内容都是不同的，并没有备份关系，数据节点的备份关系是通过多个数据节点主机存储备份来实现的。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#FF0000">     </font></b></span></div><div style="text-align: left;"><b style="font-size: 19px; text-align: -webkit-auto;">2.     数据节点多目录存放</b></div><div style="text-align: left;"><font color="#FF0000" size="4"><b><br/></b></font></div><div style="text-align: left; font-size: 16px;">     &lt;property&gt;<br/>
            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br/>
            &lt;value&gt;<b><font color="#FF0000">file://${hadoop.tmp.dir}/dfs/data</font></b>&lt;/value&gt;<br/>
            &lt;description&gt;<font color="#A600C4">Determines where on the local filesystem an DFS data node<br/>
            should store its blocks.  If this is a comma-delimited<br/>
            list of directories, then data will be stored in all named<br/>
            directories, typically on different devices. The directories should be tagged<br/>
            with corresponding storage types ([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK]) for HDFS<br/>
            storage policies. The default storage type will be DISK if the directory does<br/>
            not have a storage type tagged explicitly. Directories that do not exist will<br/>
            be created if local filesystem permission allows.</font><br/>
            &lt;/description&gt;<br/>
     &lt;/property&gt;</div><div style="text-align: left;"><br/></div><div style="text-align: left;">      <font color="#A600C4" size="4"><b>决定了本地文件系统数据节点存放块数据的位置，如果此项是一个以逗号分隔的目录列表，那么数据将会被存储在所有的目录中，典型的是存储在不同的设备上。为了满足HDFS的存储策略，这些目录应当被标记为以下的存储类型：</b></font><span style="font-size: 16px;"><b><font color="#A600C4">[SSD] / [DISK] / [ARCHIVE] / [RAM_DISK]。如果目录没有显示标明存储类型则默认的存储类型是DISK。如果目录不存在，在本地文件系统允许的情况下这些目录将会被创建。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4"><br/></font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4">     数据节点配置为多个目录并不是副本的概念，而是提供多个目录来存储数据。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4"><br/></font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4">     </font></b></span><b><span style="font-size: 16px;">dfs.datanode.data.dir = </span><span style="font-size: 16px;">file://${hadoop.tmp.dir}/dfs/data1，</span></b><b style="font-size: 16px;">file://${hadoop.tmp.dir}/dfs/data2</b></div><div style="text-align: left;"><b><br/></b></div><div style="text-align: left;"><b>     </b><span style="font-size: 16px;"> &lt;property&gt;</span></div><span style="font-size: 16px; text-align: left;">            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br style="font-size: 16px; text-align: left;"/><span style="font-size: 16px; text-align: left;">            &lt;value&gt;</span><b style="text-align: left;"><span style="font-size: 16px;">file://${hadoop.tmp.dir}/dfs/data1，</span></b><b style="text-align: left; font-size: 16px;">file://${hadoop.tmp.dir}/dfs/data2</b> <span style="font-size: 16px; text-align: left;">&lt;/value&gt;</span><br style="font-size: 16px; text-align: left;"/><span style="font-size: 16px; text-align: left;">     &lt;/property&gt;</span><div><span style="font-size: 16px; text-align: left;"><br/></span></div><div><span style="font-size: 16px; text-align: left;">     <b><font color="#FF0000">文件系统格式化时与数据节点无关，data1和data2不会被创建，当集群启动时它们才会被创建。</font></b></span></div><div><span style="font-size: 16px; text-align: left;"><b><font color="#FF0000"><br/></font></b></span></div><div style="text-align: center;"><span style="font-size: 16px; text-align: left;"><b><font color="#FF0000">     </font></b></span><img src="2017-07-17-hello-world1_files/Image [1].png" type="image/png" style="cursor: default;cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><span style="font-size: 16px;">     <b><font color="#A600C4">data1和data2的目录结构完全一致。</font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4"><br/></font></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4">     </font>① <font color="#A600C4"> </font>向hdfs中传入一个小型文件hello.txt：</b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><font color="#A600C4"><br/></font></b></span></div><div style="text-align: center;"><span style="font-size: 16px;"><b><font color="#A600C4">     </font></b></span><img src="2017-07-17-hello-world1_files/Image [2].png" type="image/png" style="cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: center;"><img src="2017-07-17-hello-world1_files/Image [3].png" type="image/png" style="cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><span style="font-size: 16px;">     <b>可以看到<font color="#FF0000">只有data1中存储有上传的文件，即blk_1073741826，而data2中没有任何存储数据</font>，因此，<font color="#FF0000">data1与data2之间并不是副本关系</font>。</b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b><br/></b></span></div><div style="text-align: left;"><span style="font-size: 16px;"><b>     ②  向hdfs中传入一个大型文件hadoop-2.7.2.tar.gz：</b></span></div><div style="text-align: center;"><span style="font-size: 16px;"><b>          </b></span><img src="2017-07-17-hello-world1_files/Image [4].png" type="image/png" style="cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><span style="font-size: 16px;">     </span><b style="font-size: 16px;">可以看到传入的文件大型为202.22MB，那么将会被分为两块，如下图所示：</b></div><div style="text-align: center;"><br/></div><div style="text-align: center;">     <img src="2017-07-17-hello-world1_files/Image [5].png" type="image/png" style="cursor: default;"/></div><div style="text-align: center;"><br/></div><div style="text-align: left;"><span style="font-size: 16px;">     </span><b style="font-size: 16px;">可以看到Block0的Block ID为1073741826，</b><b style="font-size: 16px;">Block1的Block ID为1073741827，</b><b style="font-size: 16px;">那么在数据节点的本地文件中有blk_</b><b style="font-size: 16px;">1073741826块文件和</b><b style="font-size: 16px;">blk_</b><b style="font-size: 16px;">1073741827块文件</b><b style="font-size: 16px;">，也就是在s101、s102、s103中均有</b><b style="font-size: 16px;">blk_</b><b style="font-size: 16px;">1073741826块文件</b><b style="font-size: 16px;">和</b><b style="font-size: 16px;">blk_</b><b style="font-size: 16px;">1073741827块文件。</b></div><div style="text-align: left;"><b style="font-size: 16px;"><br/></b></div><div style="text-align: left;"><b style="font-size: 16px;">    <font color="#A600C4"> 在数据节点的本地文件中，</font></b><font color="#A600C4"><b style="font-size: 16px;">blk_</b><b style="font-size: 16px;">1073741826块文件</b><b style="font-size: 16px;">和</b><b style="font-size: 16px;">blk_</b><b style="font-size: 16px;">1073741827块文件并没有被存储在同一个data文件下，这说明当指定多个数据节点目录文件时，块文件的存放不是存满一个再存一个，而是data1和data2中都有，这是一种并发机制，速度更快。</b></font></div><div style="text-align: left;"><font color="#A600C4"><b style="font-size: 16px;"><br/></b></font></div><div style="text-align: left;"><b style="font-size: 16px;"><font color="#A600C4">     </font>可以看Block0的大小134217728Byte正好是128MB，Block1的大小77829046Byte为74.22MB，加起来正好是原文件大小。</b></div><div style="text-align: left;"><font size="4"><b><br/></b></font></div></span>
</div></body></html> 